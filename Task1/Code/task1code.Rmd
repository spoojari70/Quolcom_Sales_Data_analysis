---
title: "Taskone"
author: "sairaj"
date: "2025-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(readxl)
```

```{r}
filePath <- "C:/Users/Acer/Quolcom/Task1/Data/"

# Use read_excel for the .xlsx file
transactionData <- read_excel(paste0(filePath, "QVI_transaction_data.xlsx"))

# Use fread for the .csv file (as previously confirmed)
customerData <- fread(paste0(filePath, "QVI_purchase_behaviour.csv"))

# If you need transactionData to be a data.table (recommended for consistency):
setDT(transactionData)
```

```{r}
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899-12-30")
```

```{r}
#### Examine PROD_NAME
transactionData[, .N, PROD_NAME]

#### Examine the words in PROD_NAME to see if there are any incorrect entries
productWords <- data.table(unlist(strsplit(unique(transactionData[, PROD_NAME]), " ")))
setnames(productWords, 'words')

#### Removing digits
productWords <- productWords[grepl("\\d", words) == FALSE, ]

#### Removing special characters (keeping only alphabetical words)
productWords <- productWords[grepl("[:alpha:]", words), ]

#### Look at the most common words
productWords[, .N, words][order(-N)]

#### Remove salsa products
# Create a temporary logical column 'SALSA', filter, then remove the column
transactionData[, SALSA := grepl("salsa", tolower(PROD_NAME))]
transactionData <- transactionData[SALSA == FALSE, ][, SALSA := NULL]
```

```{r}
#### Summarise the data to check for nulls and possible outliers
summary(transactionData)

#### Filter the dataset to find the outlier (PROD_QTY == 200)
transactionData[PROD_QTY == 200, ]

#### See if the customer has had other transactions
transactionData[LYLTY_CARD_NBR == 226000, ]

#### Filter out the commercial customer based on the loyalty card number
transactionData <- transactionData[LYLTY_CARD_NBR != 226000, ]

#### Re-examine transaction data summary
summary(transactionData)
```

```{r}
#### Count the number of transactions by date
transactions_count <- transactionData[, .N, by = DATE][order(DATE)]

#### Create a sequence of all dates and join with transaction counts
allDates <- data.table(seq(as.Date("2018/07/01"), as.Date("2019/06/30"), by = "day"))
setnames(allDates, "DATE")
transactions_by_day <- merge(allDates, transactions_count, all.x = TRUE)
transactions_by_day[is.na(N), N := 0] # Replace missing counts with 0

#### Setting plot themes to format graphs
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))

#### Plot transactions over time
ggplot(transactions_by_day, aes(x = DATE, y = N)) +
  geom_line() +
  labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
  scale_x_date(breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

#### Filter to December and look at individual days (to confirm Christmas Day drop)
ggplot(transactions_by_day[month(DATE) == 12, ], aes(x = DATE, y = N)) +
  geom_line() +
  labs(x = "Day", y = "Number of transactions", title = "Transactions over time (Dec 2018)") +
  scale_x_date(breaks = "1 day") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

```{r}
#### Pack size
# Use parse_number from readr to extract digits
transactionData[, PACK_SIZE := parse_number(PROD_NAME)]

#### Check if the pack sizes look sensible
transactionData[, .N, PACK_SIZE][order(PACK_SIZE)]

#### Plot a histogram of PACK_SIZE
hist(transactionData[, PACK_SIZE])
```

```{r}
#### Brands
# Extracts the first word before a space, then converts to upper case
transactionData[, BRAND := toupper(substr(PROD_NAME, 1, regexpr(pattern = ' ', PROD_NAME) - 1))]

#### Checking brands
transactionData[, .N, by = BRAND][order(-N)]

#### Clean brand names
transactionData[BRAND == "RED", BRAND := "RRD"]
transactionData[BRAND == "SNBTS", BRAND := "SUNBITES"]
transactionData[BRAND == "INFZNS", BRAND := "INFUZIONS"]
transactionData[BRAND == "WW", BRAND := "WOOLWORTHS"]
transactionData[BRAND == "SMITH", BRAND := "SMITHS"]
transactionData[BRAND == "NCC", BRAND := "NATURAL"]
transactionData[BRAND == "DORITO", BRAND := "DORITOS"]
transactionData[BRAND == "GRAIN", BRAND := "GRNWVES"]

#### Check again
transactionData[, .N, by = BRAND][order(BRAND)]
```

```{r}
#### Examining customer data
str(customerData)
summary(customerData)

#### Examining the values of LIFESTAGE and PREMIUM_CUSTOMER
customerData[, .N, by = LIFESTAGE][order(-N)]
customerData[, .N, by = PREMIUM_CUSTOMER][order(-N)]
```

```{r}
#### Merge transaction data to customer data
data <- merge(transactionData, customerData, all.x = TRUE)

#### Check for unmatched customers (nulls)
data[is.null(LIFESTAGE), .N]
data[is.null(PREMIUM_CUSTOMER), .N]

# Optional: Save the merged data for Task 2
# fwrite(data, paste0(filePath,"QVI_data.csv"))
```

```{r}
p_sales <- ggplot(data = sales) +
  geom_mosaic(aes(weight = SALES, x = product(PREMIUM_CUSTOMER, LIFESTAGE),
                  fill = PREMIUM_CUSTOMER)) +
  labs(x = "Lifestage", y = "Premium customer flag", title = "Proportion of sales") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

```{r}
# View the calculated sales for proportion
sales[, PROPORTION := round(SALES / sum(SALES) * 100, 2)]
sales[order(-PROPORTION)]
```

```{r}
#### Average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
avg_units <- data[, .(AVG = sum(PROD_QTY)/uniqueN(LYLTY_CARD_NBR)),
                  .(LIFESTAGE, PREMIUM_CUSTOMER)][order(-AVG)]

# Print the resulting data table
print(avg_units)

#### Create plot
ggplot(data = avg_units, aes(x = LIFESTAGE, y = AVG, fill = PREMIUM_CUSTOMER)) +
  # Use stat="identity" since AVG is pre-calculated
  geom_bar(position = position_dodge(), stat = "identity") +
  labs(x = "Lifestage", y = "Avg units per customer", title = "Units per customer") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

```{r}
#### Average price per unit by LIFESTAGE and PREMIUM_CUSTOMER
avg_price <- data[, .(AVG = sum(TOT_SALES)/sum(PROD_QTY)), .(LIFESTAGE,
                                                             PREMIUM_CUSTOMER)][order(-AVG)]

#### Create plot
ggplot(data = avg_price, aes(x = LIFESTAGE, y = AVG, fill = PREMIUM_CUSTOMER)) +
  geom_bar(position = position_dodge(), stat = "identity") +
  labs(x = "Lifestage", y = "Avg price per unit", title = "Price per unit") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

#### Perform an independent t-test (Mainstream vs Budget/Premium midage/young singles/couples)
pricePerUnit <- data[, price := TOT_SALES/PROD_QTY]

t.test(data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES")
           & PREMIUM_CUSTOMER == "Mainstream", price]
       , data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES")
              & PREMIUM_CUSTOMER != "Mainstream", price]
       , alternative = "greater")
```

```{r}
#### Deep dive into Mainstream, young singles/couples
segment1 <- data[LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER ==
                   "Mainstream",]
other <- data[!(LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER ==
                  "Mainstream"),]

#### Brand affinity compared to the rest of the population
quantity_segment1 <- segment1[, sum(PROD_QTY)]
quantity_other <- other[, sum(PROD_QTY)]

quantity_segment1_by_brand <- segment1[, .(targetSegment =
                                              sum(PROD_QTY)/quantity_segment1), by = BRAND]
quantity_other_by_brand <- other[, .(other = sum(PROD_QTY)/quantity_other), by
                                 = BRAND]

brand_proportions <- merge(quantity_segment1_by_brand,
                           quantity_other_by_brand)[, affinityToBrand := targetSegment/other]
brand_proportions[order(-affinityToBrand)]
```

```{r}
#### Preferred pack size compared to the rest of the population
quantity_segment1_by_pack <- segment1[, .(targetSegment =
                                            sum(PROD_QTY)/quantity_segment1), by = PACK_SIZE]
quantity_other_by_pack <- other[, .(other = sum(PROD_QTY)/quantity_other), by =
                                  PACK_SIZE]

pack_proportions <- merge(quantity_segment1_by_pack, quantity_other_by_pack)[,
                                                                              affinityToPack := targetSegment/other]
pack_proportions[order(-affinityToPack)]

# Final check on the most popular pack size for the segment
data[PACK_SIZE == 270, unique(PROD_NAME)]
```
